<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url('https://themes.googleusercontent.com/fonts/css?kit=yrPxF2fzIbKO47OcVFfZ2CvhBULzVSj67-CyYQmQBzclLT34rKZNjX_x5wwcqB1FJcp4QFgPPqKvq4Bp_6u4rQ');ol.lst-kix_j02jvw57j8n8-1.start{counter-reset:lst-ctn-kix_j02jvw57j8n8-1 0}.lst-kix_cljnzgcrdgzc-1>li{counter-increment:lst-ctn-kix_cljnzgcrdgzc-1}.lst-kix_neq4xbg0drvj-0>li{counter-increment:lst-ctn-kix_neq4xbg0drvj-0}ol.lst-kix_7u13rf1qidgz-5{list-style-type:none}ol.lst-kix_7u13rf1qidgz-6{list-style-type:none}ol.lst-kix_7u13rf1qidgz-7{list-style-type:none}ol.lst-kix_7u13rf1qidgz-8{list-style-type:none}ol.lst-kix_neq4xbg0drvj-0.start{counter-reset:lst-ctn-kix_neq4xbg0drvj-0 0}ol.lst-kix_cljnzgcrdgzc-5.start{counter-reset:lst-ctn-kix_cljnzgcrdgzc-5 0}.lst-kix_ng197j8vcofz-6>li{counter-increment:lst-ctn-kix_ng197j8vcofz-6}.lst-kix_neq4xbg0drvj-1>li:before{content:"" counter(lst-ctn-kix_neq4xbg0drvj-1,lower-latin) ". "}.lst-kix_neq4xbg0drvj-2>li:before{content:"" counter(lst-ctn-kix_neq4xbg0drvj-2,lower-roman) ". "}.lst-kix_neq4xbg0drvj-3>li:before{content:"" counter(lst-ctn-kix_neq4xbg0drvj-3,decimal) ". "}.lst-kix_7u13rf1qidgz-6>li{counter-increment:lst-ctn-kix_7u13rf1qidgz-6}ol.lst-kix_ng197j8vcofz-7.start{counter-reset:lst-ctn-kix_ng197j8vcofz-7 0}.lst-kix_j02jvw57j8n8-6>li:before{content:"" counter(lst-ctn-kix_j02jvw57j8n8-6,decimal) ". "}.lst-kix_j02jvw57j8n8-5>li:before{content:"" counter(lst-ctn-kix_j02jvw57j8n8-5,lower-roman) ". "}.lst-kix_neq4xbg0drvj-0>li:before{content:"" counter(lst-ctn-kix_neq4xbg0drvj-0,decimal) ". "}.lst-kix_j02jvw57j8n8-3>li:before{content:"" counter(lst-ctn-kix_j02jvw57j8n8-3,decimal) ". "}.lst-kix_j02jvw57j8n8-4>li:before{content:"" counter(lst-ctn-kix_j02jvw57j8n8-4,lower-latin) ". "}ol.lst-kix_7u13rf1qidgz-5.start{counter-reset:lst-ctn-kix_7u13rf1qidgz-5 0}ol.lst-kix_neq4xbg0drvj-5.start{counter-reset:lst-ctn-kix_neq4xbg0drvj-5 0}.lst-kix_j02jvw57j8n8-7>li:before{content:"" counter(lst-ctn-kix_j02jvw57j8n8-7,lower-latin) ". "}.lst-kix_j02jvw57j8n8-8>li:before{content:"" counter(lst-ctn-kix_j02jvw57j8n8-8,lower-roman) ". "}ol.lst-kix_ng197j8vcofz-0{list-style-type:none}ol.lst-kix_ng197j8vcofz-2{list-style-type:none}ol.lst-kix_ng197j8vcofz-1{list-style-type:none}ol.lst-kix_ng197j8vcofz-4{list-style-type:none}ol.lst-kix_ng197j8vcofz-3{list-style-type:none}ol.lst-kix_7u13rf1qidgz-4.start{counter-reset:lst-ctn-kix_7u13rf1qidgz-4 0}.lst-kix_cljnzgcrdgzc-8>li:before{content:"" counter(lst-ctn-kix_cljnzgcrdgzc-8,lower-roman) ". "}.lst-kix_cljnzgcrdgzc-7>li:before{content:"" counter(lst-ctn-kix_cljnzgcrdgzc-7,lower-latin) ". "}.lst-kix_ng197j8vcofz-4>li{counter-increment:lst-ctn-kix_ng197j8vcofz-4}.lst-kix_j02jvw57j8n8-1>li:before{content:"" counter(lst-ctn-kix_j02jvw57j8n8-1,lower-latin) ". "}ol.lst-kix_cljnzgcrdgzc-0.start{counter-reset:lst-ctn-kix_cljnzgcrdgzc-0 0}.lst-kix_j02jvw57j8n8-2>li:before{content:"" counter(lst-ctn-kix_j02jvw57j8n8-2,lower-roman) ". "}ol.lst-kix_neq4xbg0drvj-6.start{counter-reset:lst-ctn-kix_neq4xbg0drvj-6 0}ol.lst-kix_ng197j8vcofz-6{list-style-type:none}ol.lst-kix_ng197j8vcofz-5{list-style-type:none}ol.lst-kix_ng197j8vcofz-8{list-style-type:none}ol.lst-kix_ng197j8vcofz-7{list-style-type:none}.lst-kix_j02jvw57j8n8-0>li:before{content:"\0025cf  "}.lst-kix_cljnzgcrdgzc-1>li:before{content:"" counter(lst-ctn-kix_cljnzgcrdgzc-1,lower-latin) ". "}ol.lst-kix_neq4xbg0drvj-1.start{counter-reset:lst-ctn-kix_neq4xbg0drvj-1 0}.lst-kix_cljnzgcrdgzc-3>li{counter-increment:lst-ctn-kix_cljnzgcrdgzc-3}ul.lst-kix_j02jvw57j8n8-0{list-style-type:none}.lst-kix_cljnzgcrdgzc-0>li:before{content:"" counter(lst-ctn-kix_cljnzgcrdgzc-0,decimal) ". "}.lst-kix_cljnzgcrdgzc-5>li:before{content:"" counter(lst-ctn-kix_cljnzgcrdgzc-5,lower-roman) ". "}.lst-kix_7u13rf1qidgz-4>li{counter-increment:lst-ctn-kix_7u13rf1qidgz-4}.lst-kix_cljnzgcrdgzc-6>li:before{content:"" counter(lst-ctn-kix_cljnzgcrdgzc-6,decimal) ". "}.lst-kix_cljnzgcrdgzc-2>li:before{content:"" counter(lst-ctn-kix_cljnzgcrdgzc-2,lower-roman) ". "}.lst-kix_neq4xbg0drvj-4>li{counter-increment:lst-ctn-kix_neq4xbg0drvj-4}ol.lst-kix_ng197j8vcofz-6.start{counter-reset:lst-ctn-kix_ng197j8vcofz-6 0}.lst-kix_cljnzgcrdgzc-3>li:before{content:"" counter(lst-ctn-kix_cljnzgcrdgzc-3,decimal) ". "}.lst-kix_neq4xbg0drvj-7>li{counter-increment:lst-ctn-kix_neq4xbg0drvj-7}.lst-kix_j02jvw57j8n8-8>li{counter-increment:lst-ctn-kix_j02jvw57j8n8-8}.lst-kix_cljnzgcrdgzc-4>li:before{content:"" counter(lst-ctn-kix_cljnzgcrdgzc-4,lower-latin) ". "}.lst-kix_j02jvw57j8n8-3>li{counter-increment:lst-ctn-kix_j02jvw57j8n8-3}.lst-kix_cljnzgcrdgzc-7>li{counter-increment:lst-ctn-kix_cljnzgcrdgzc-7}ol.lst-kix_neq4xbg0drvj-4.start{counter-reset:lst-ctn-kix_neq4xbg0drvj-4 0}ol.lst-kix_neq4xbg0drvj-1{list-style-type:none}ol.lst-kix_neq4xbg0drvj-0{list-style-type:none}ol.lst-kix_neq4xbg0drvj-3{list-style-type:none}ol.lst-kix_neq4xbg0drvj-2{list-style-type:none}ol.lst-kix_neq4xbg0drvj-5{list-style-type:none}ol.lst-kix_neq4xbg0drvj-4{list-style-type:none}ol.lst-kix_neq4xbg0drvj-7{list-style-type:none}ol.lst-kix_ng197j8vcofz-3.start{counter-reset:lst-ctn-kix_ng197j8vcofz-3 0}ol.lst-kix_neq4xbg0drvj-6{list-style-type:none}ol.lst-kix_neq4xbg0drvj-8{list-style-type:none}ol.lst-kix_j02jvw57j8n8-5.start{counter-reset:lst-ctn-kix_j02jvw57j8n8-5 0}.lst-kix_ng197j8vcofz-0>li{counter-increment:lst-ctn-kix_ng197j8vcofz-0}ol.lst-kix_j02jvw57j8n8-8.start{counter-reset:lst-ctn-kix_j02jvw57j8n8-8 0}.lst-kix_j02jvw57j8n8-4>li{counter-increment:lst-ctn-kix_j02jvw57j8n8-4}.lst-kix_cljnzgcrdgzc-8>li{counter-increment:lst-ctn-kix_cljnzgcrdgzc-8}ol.lst-kix_7u13rf1qidgz-1.start{counter-reset:lst-ctn-kix_7u13rf1qidgz-1 0}.lst-kix_7u13rf1qidgz-8>li{counter-increment:lst-ctn-kix_7u13rf1qidgz-8}ol.lst-kix_ng197j8vcofz-1.start{counter-reset:lst-ctn-kix_ng197j8vcofz-1 0}.lst-kix_7u13rf1qidgz-1>li:before{content:"" counter(lst-ctn-kix_7u13rf1qidgz-1,lower-latin) ". "}.lst-kix_ng197j8vcofz-0>li:before{content:"" counter(lst-ctn-kix_ng197j8vcofz-0,decimal) ". "}ol.lst-kix_j02jvw57j8n8-6.start{counter-reset:lst-ctn-kix_j02jvw57j8n8-6 0}.lst-kix_7u13rf1qidgz-2>li{counter-increment:lst-ctn-kix_7u13rf1qidgz-2}.lst-kix_ng197j8vcofz-2>li:before{content:"" counter(lst-ctn-kix_ng197j8vcofz-2,lower-roman) ". "}.lst-kix_7u13rf1qidgz-5>li:before{content:"" counter(lst-ctn-kix_7u13rf1qidgz-5,lower-roman) ". "}.lst-kix_neq4xbg0drvj-3>li{counter-increment:lst-ctn-kix_neq4xbg0drvj-3}.lst-kix_7u13rf1qidgz-3>li:before{content:"" counter(lst-ctn-kix_7u13rf1qidgz-3,decimal) ". "}.lst-kix_ng197j8vcofz-6>li:before{content:"" counter(lst-ctn-kix_ng197j8vcofz-6,decimal) ". "}.lst-kix_neq4xbg0drvj-8>li{counter-increment:lst-ctn-kix_neq4xbg0drvj-8}.lst-kix_ng197j8vcofz-4>li:before{content:"" counter(lst-ctn-kix_ng197j8vcofz-4,lower-latin) ". "}.lst-kix_ng197j8vcofz-8>li:before{content:"" counter(lst-ctn-kix_ng197j8vcofz-8,lower-roman) ". "}.lst-kix_gf5co4b6g2uq-1>li:before{content:"\0025cb  "}.lst-kix_neq4xbg0drvj-2>li{counter-increment:lst-ctn-kix_neq4xbg0drvj-2}.lst-kix_ng197j8vcofz-5>li{counter-increment:lst-ctn-kix_ng197j8vcofz-5}.lst-kix_neq4xbg0drvj-5>li:before{content:"" counter(lst-ctn-kix_neq4xbg0drvj-5,lower-roman) ". "}ol.lst-kix_j02jvw57j8n8-7.start{counter-reset:lst-ctn-kix_j02jvw57j8n8-7 0}ol.lst-kix_ng197j8vcofz-2.start{counter-reset:lst-ctn-kix_ng197j8vcofz-2 0}.lst-kix_gf5co4b6g2uq-3>li:before{content:"\0025cf  "}.lst-kix_neq4xbg0drvj-7>li:before{content:"" counter(lst-ctn-kix_neq4xbg0drvj-7,lower-latin) ". "}.lst-kix_gf5co4b6g2uq-5>li:before{content:"\0025a0  "}ol.lst-kix_7u13rf1qidgz-0.start{counter-reset:lst-ctn-kix_7u13rf1qidgz-0 0}.lst-kix_gf5co4b6g2uq-7>li:before{content:"\0025cb  "}.lst-kix_7u13rf1qidgz-7>li:before{content:"" counter(lst-ctn-kix_7u13rf1qidgz-7,lower-latin) ". "}.lst-kix_ng197j8vcofz-7>li{counter-increment:lst-ctn-kix_ng197j8vcofz-7}ol.lst-kix_cljnzgcrdgzc-8.start{counter-reset:lst-ctn-kix_cljnzgcrdgzc-8 0}.lst-kix_7u13rf1qidgz-5>li{counter-increment:lst-ctn-kix_7u13rf1qidgz-5}ol.lst-kix_7u13rf1qidgz-2.start{counter-reset:lst-ctn-kix_7u13rf1qidgz-2 0}ol.lst-kix_cljnzgcrdgzc-2.start{counter-reset:lst-ctn-kix_cljnzgcrdgzc-2 0}ol.lst-kix_neq4xbg0drvj-3.start{counter-reset:lst-ctn-kix_neq4xbg0drvj-3 0}ol.lst-kix_neq4xbg0drvj-8.start{counter-reset:lst-ctn-kix_neq4xbg0drvj-8 0}.lst-kix_7u13rf1qidgz-3>li{counter-increment:lst-ctn-kix_7u13rf1qidgz-3}.lst-kix_j02jvw57j8n8-7>li{counter-increment:lst-ctn-kix_j02jvw57j8n8-7}ol.lst-kix_ng197j8vcofz-4.start{counter-reset:lst-ctn-kix_ng197j8vcofz-4 0}.lst-kix_cljnzgcrdgzc-2>li{counter-increment:lst-ctn-kix_cljnzgcrdgzc-2}ol.lst-kix_7u13rf1qidgz-8.start{counter-reset:lst-ctn-kix_7u13rf1qidgz-8 0}ol.lst-kix_j02jvw57j8n8-1{list-style-type:none}ol.lst-kix_j02jvw57j8n8-3{list-style-type:none}ol.lst-kix_j02jvw57j8n8-2{list-style-type:none}ol.lst-kix_neq4xbg0drvj-2.start{counter-reset:lst-ctn-kix_neq4xbg0drvj-2 0}ol.lst-kix_j02jvw57j8n8-5{list-style-type:none}ol.lst-kix_j02jvw57j8n8-4{list-style-type:none}ol.lst-kix_j02jvw57j8n8-7{list-style-type:none}ol.lst-kix_j02jvw57j8n8-6{list-style-type:none}ol.lst-kix_j02jvw57j8n8-8{list-style-type:none}ol.lst-kix_cljnzgcrdgzc-7.start{counter-reset:lst-ctn-kix_cljnzgcrdgzc-7 0}ol.lst-kix_j02jvw57j8n8-3.start{counter-reset:lst-ctn-kix_j02jvw57j8n8-3 0}.lst-kix_ng197j8vcofz-3>li{counter-increment:lst-ctn-kix_ng197j8vcofz-3}ol.lst-kix_ng197j8vcofz-5.start{counter-reset:lst-ctn-kix_ng197j8vcofz-5 0}ol.lst-kix_ng197j8vcofz-0.start{counter-reset:lst-ctn-kix_ng197j8vcofz-0 0}.lst-kix_cljnzgcrdgzc-0>li{counter-increment:lst-ctn-kix_cljnzgcrdgzc-0}ul.lst-kix_gf5co4b6g2uq-2{list-style-type:none}.lst-kix_neq4xbg0drvj-1>li{counter-increment:lst-ctn-kix_neq4xbg0drvj-1}ul.lst-kix_gf5co4b6g2uq-3{list-style-type:none}ul.lst-kix_gf5co4b6g2uq-0{list-style-type:none}ul.lst-kix_gf5co4b6g2uq-1{list-style-type:none}ol.lst-kix_j02jvw57j8n8-4.start{counter-reset:lst-ctn-kix_j02jvw57j8n8-4 0}ul.lst-kix_gf5co4b6g2uq-8{list-style-type:none}ul.lst-kix_gf5co4b6g2uq-6{list-style-type:none}ul.lst-kix_gf5co4b6g2uq-7{list-style-type:none}ul.lst-kix_gf5co4b6g2uq-4{list-style-type:none}.lst-kix_7u13rf1qidgz-7>li{counter-increment:lst-ctn-kix_7u13rf1qidgz-7}.lst-kix_j02jvw57j8n8-2>li{counter-increment:lst-ctn-kix_j02jvw57j8n8-2}.lst-kix_cljnzgcrdgzc-6>li{counter-increment:lst-ctn-kix_cljnzgcrdgzc-6}ul.lst-kix_gf5co4b6g2uq-5{list-style-type:none}ol.lst-kix_neq4xbg0drvj-7.start{counter-reset:lst-ctn-kix_neq4xbg0drvj-7 0}ol.lst-kix_cljnzgcrdgzc-1.start{counter-reset:lst-ctn-kix_cljnzgcrdgzc-1 0}.lst-kix_j02jvw57j8n8-5>li{counter-increment:lst-ctn-kix_j02jvw57j8n8-5}ol.lst-kix_7u13rf1qidgz-3.start{counter-reset:lst-ctn-kix_7u13rf1qidgz-3 0}.lst-kix_7u13rf1qidgz-1>li{counter-increment:lst-ctn-kix_7u13rf1qidgz-1}.lst-kix_ng197j8vcofz-1>li{counter-increment:lst-ctn-kix_ng197j8vcofz-1}.lst-kix_neq4xbg0drvj-6>li{counter-increment:lst-ctn-kix_neq4xbg0drvj-6}.lst-kix_neq4xbg0drvj-5>li{counter-increment:lst-ctn-kix_neq4xbg0drvj-5}ol.lst-kix_j02jvw57j8n8-2.start{counter-reset:lst-ctn-kix_j02jvw57j8n8-2 0}.lst-kix_7u13rf1qidgz-0>li{counter-increment:lst-ctn-kix_7u13rf1qidgz-0}ol.lst-kix_cljnzgcrdgzc-1{list-style-type:none}ol.lst-kix_cljnzgcrdgzc-0{list-style-type:none}.lst-kix_j02jvw57j8n8-1>li{counter-increment:lst-ctn-kix_j02jvw57j8n8-1}.lst-kix_cljnzgcrdgzc-5>li{counter-increment:lst-ctn-kix_cljnzgcrdgzc-5}ol.lst-kix_cljnzgcrdgzc-6.start{counter-reset:lst-ctn-kix_cljnzgcrdgzc-6 0}ol.lst-kix_cljnzgcrdgzc-3{list-style-type:none}ol.lst-kix_cljnzgcrdgzc-2{list-style-type:none}ol.lst-kix_cljnzgcrdgzc-5{list-style-type:none}ol.lst-kix_cljnzgcrdgzc-4{list-style-type:none}ol.lst-kix_cljnzgcrdgzc-7{list-style-type:none}ol.lst-kix_cljnzgcrdgzc-6{list-style-type:none}ol.lst-kix_cljnzgcrdgzc-8{list-style-type:none}ol.lst-kix_cljnzgcrdgzc-3.start{counter-reset:lst-ctn-kix_cljnzgcrdgzc-3 0}.lst-kix_7u13rf1qidgz-2>li:before{content:"" counter(lst-ctn-kix_7u13rf1qidgz-2,lower-roman) ". "}.lst-kix_j02jvw57j8n8-6>li{counter-increment:lst-ctn-kix_j02jvw57j8n8-6}.lst-kix_ng197j8vcofz-1>li:before{content:"" counter(lst-ctn-kix_ng197j8vcofz-1,lower-latin) ". "}ol.lst-kix_ng197j8vcofz-8.start{counter-reset:lst-ctn-kix_ng197j8vcofz-8 0}.lst-kix_7u13rf1qidgz-4>li:before{content:"" counter(lst-ctn-kix_7u13rf1qidgz-4,lower-latin) ". "}.lst-kix_ng197j8vcofz-5>li:before{content:"" counter(lst-ctn-kix_ng197j8vcofz-5,lower-roman) ". "}ol.lst-kix_7u13rf1qidgz-7.start{counter-reset:lst-ctn-kix_7u13rf1qidgz-7 0}.lst-kix_ng197j8vcofz-3>li:before{content:"" counter(lst-ctn-kix_ng197j8vcofz-3,decimal) ". "}.lst-kix_ng197j8vcofz-7>li:before{content:"" counter(lst-ctn-kix_ng197j8vcofz-7,lower-latin) ". "}.lst-kix_gf5co4b6g2uq-2>li:before{content:"\0025a0  "}.lst-kix_7u13rf1qidgz-0>li:before{content:"" counter(lst-ctn-kix_7u13rf1qidgz-0,decimal) ". "}.lst-kix_gf5co4b6g2uq-0>li:before{content:"\0025cf  "}.lst-kix_cljnzgcrdgzc-4>li{counter-increment:lst-ctn-kix_cljnzgcrdgzc-4}.lst-kix_neq4xbg0drvj-4>li:before{content:"" counter(lst-ctn-kix_neq4xbg0drvj-4,lower-latin) ". "}.lst-kix_neq4xbg0drvj-6>li:before{content:"" counter(lst-ctn-kix_neq4xbg0drvj-6,decimal) ". "}.lst-kix_ng197j8vcofz-2>li{counter-increment:lst-ctn-kix_ng197j8vcofz-2}.lst-kix_neq4xbg0drvj-8>li:before{content:"" counter(lst-ctn-kix_neq4xbg0drvj-8,lower-roman) ". "}ol.lst-kix_cljnzgcrdgzc-4.start{counter-reset:lst-ctn-kix_cljnzgcrdgzc-4 0}.lst-kix_gf5co4b6g2uq-4>li:before{content:"\0025cb  "}ol.lst-kix_7u13rf1qidgz-0{list-style-type:none}ol.lst-kix_7u13rf1qidgz-1{list-style-type:none}ol.lst-kix_7u13rf1qidgz-6.start{counter-reset:lst-ctn-kix_7u13rf1qidgz-6 0}ol.lst-kix_7u13rf1qidgz-2{list-style-type:none}.lst-kix_gf5co4b6g2uq-6>li:before{content:"\0025cf  "}ol.lst-kix_7u13rf1qidgz-3{list-style-type:none}ol.lst-kix_7u13rf1qidgz-4{list-style-type:none}.lst-kix_7u13rf1qidgz-6>li:before{content:"" counter(lst-ctn-kix_7u13rf1qidgz-6,decimal) ". "}.lst-kix_7u13rf1qidgz-8>li:before{content:"" counter(lst-ctn-kix_7u13rf1qidgz-8,lower-roman) ". "}.lst-kix_gf5co4b6g2uq-8>li:before{content:"\0025a0  "}.lst-kix_ng197j8vcofz-8>li{counter-increment:lst-ctn-kix_ng197j8vcofz-8}ol{margin:0;padding:0}table td,table th{padding:0}.c24{margin-left:-0.8pt;padding-top:24pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:left;margin-right:89.2pt}.c25{margin-left:-0.8pt;padding-top:24pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left;margin-right:89.2pt}.c33{margin-left:-0.8pt;padding-top:3pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:left}.c17{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Open Sans";font-style:normal}.c20{margin-left:28pt;padding-top:12pt;padding-bottom:12pt;line-height:1.5;orphans:2;widows:2;text-align:left}.c8{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Open Sans";font-style:normal}.c41{color:#666666;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Economica";font-style:normal}.c26{margin-left:-0.8pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c23{margin-left:-0.8pt;padding-top:10pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:center}.c38{color:#999999;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Economica";font-style:normal}.c2{color:#8c7252;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Open Sans";font-style:normal}.c32{margin-left:27pt;padding-top:12pt;padding-bottom:12pt;line-height:1.5;orphans:2;widows:2;text-align:left}.c10{margin-left:-0.8pt;padding-top:10pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:left}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Open Sans";font-style:normal}.c39{margin-left:-0.8pt;padding-top:30pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c15{margin-left:18pt;padding-top:3pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c45{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Open Sans";font-style:normal}.c9{padding-top:10pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c44{padding-top:10pt;padding-bottom:4pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c36{font-weight:400;text-decoration:none;vertical-align:baseline;font-size:13.5pt;font-family:"Arial";font-style:normal}.c46{padding-top:4pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c14{font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Open Sans";font-style:normal}.c35{color:#000000;text-decoration:none;vertical-align:baseline;font-size:30pt;font-family:"Economica";font-style:normal}.c34{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c30{padding-top:10pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:left}.c27{color:#000000;text-decoration:none;vertical-align:baseline;font-size:11pt;font-style:normal}.c37{padding-top:0pt;padding-bottom:19pt;line-height:1.5;text-align:left}.c47{font-size:11.5pt;font-family:"Arial";color:#006699;font-weight:400}.c28{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c43{text-decoration:none;vertical-align:baseline;font-size:11pt;font-style:normal}.c0{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c18{font-size:11.5pt;font-family:"Arial";font-weight:700}.c40{color:#666666;font-size:24pt}.c11{font-weight:700;font-family:"Times New Roman"}.c5{color:inherit;text-decoration:inherit}.c12{font-family:"Courier New";font-weight:400}.c4{color:#212121;font-style:italic}.c1{background-color:#ffffff;color:#333333}.c31{font-family:"Times New Roman";font-weight:400}.c7{background-color:#ffffff}.c13{color:#212121}.c21{color:#292929}.c22{font-weight:700}.c6{font-style:italic}.c29{height:16pt}.c19{text-indent:0.8pt}.c16{height:11pt}.c42{margin-left:-0.8pt}.title{padding-top:0pt;color:#000000;font-size:30pt;padding-bottom:0pt;font-family:"Economica";line-height:1.0;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#999999;font-size:14pt;padding-bottom:0pt;font-family:"Economica";line-height:1.0;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Open Sans"}p{margin:0;color:#000000;font-size:11pt;font-family:"Open Sans"}h1{padding-top:10pt;color:#000000;font-weight:700;font-size:16pt;padding-bottom:0pt;font-family:"Open Sans";line-height:1.5;orphans:2;widows:2;text-align:left}h2{padding-top:24pt;color:#8c7252;font-weight:700;font-size:13pt;padding-bottom:0pt;font-family:"Open Sans";line-height:1.0;orphans:2;widows:2;text-align:left}h3{padding-top:10pt;color:#8c7252;font-weight:700;font-size:12pt;padding-bottom:0pt;font-family:"Open Sans";line-height:1.5;orphans:2;widows:2;text-align:left}h4{padding-top:8pt;-webkit-text-decoration-skip:none;color:#666666;text-decoration:underline;font-size:11pt;padding-bottom:0pt;line-height:1.5;page-break-after:avoid;text-decoration-skip-ink:none;font-family:"Trebuchet MS";orphans:2;widows:2;text-align:left}h5{padding-top:8pt;color:#666666;font-size:11pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:8pt;color:#666666;font-size:11pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.5;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c0"><div><p class="c16 c39 subtitle" id="h.leajue2ys1lr"><span class="c38"></span></p><p class="c26"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 2.67px;"><img alt="" src="images/image3.png" style="width: 624.00px; height: 2.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="horizontal line"></span></p></div><p class="c26"><span class="c41">STAT 3612 Final Report</span></p><p class="c34 title" id="h.mbjsiz6n6jlo"><span class="c22">FICO HELOC Interpretable Machine Learning</span></p><p class="c34 c42 subtitle" id="h.vb8p0lepu9vn"><span class="c40">Statistical Contemplation of Financial Data Modelling</span></p><p class="c33"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 4.00px;"><img alt="" src="images/image2.png" style="width: 624.00px; height: 4.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="horizontal line"></span></p><p class="c23"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 310.67px; height: 162.67px;"><img alt="The University of Hong Kong (HKU)" src="images/image1.png" style="width: 310.67px; height: 162.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c23"><span class="c27 c11">GROUP 3612202004</span></p><p class="c23"><span class="c11">Choi Suhyun </span><span class="c31">(</span><span class="c31 c7 c13">3035554658</span><span class="c31">)</span></p><p class="c23"><span class="c11">Chong Inbum </span><span class="c31">(3035553355)</span><span class="c27 c11">&nbsp; &nbsp;</span></p><p class="c23"><span class="c11 c7 c13">Kathleen Low Zi Yi </span><span class="c7 c13 c31">(3035549017)</span><span class="c43 c11 c7 c13">&nbsp;</span></p><p class="c23"><span class="c11 c7 c13">Kim Sunghyun </span><span class="c31 c7 c13">(3035603526)</span></p><p class="c23"><span class="c11 c7 c13">Beatrice Wong Chi Kan </span><span class="c31 c7 c13 c43">(3035374436)</span></p><p class="c33"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 4.00px;"><img alt="" src="images/image2.png" style="width: 624.00px; height: 4.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="horizontal line"></span></p><h1 class="c10" id="h.arolcxe0i15c"><span class="c17">Abstract</span></h1><p class="c10 c19"><span>Due to the nature of the financial market, any decision process within the machine learning model has to be explainable. This report offers the overall contemplation of widely-used machine learning techniques in terms of model performance interpretability. It explores the two sets of models: with and without monotonicity constraints. We apply the models to the FICO HELOC dataset, which divides the group of people based on the credibility criteria. </span></p><h1 class="c10 c29" id="h.la5jp5tnimjw"><span class="c17"></span></h1><h1 class="c10" id="h.6ks17bycdnei"><span class="c17">Table of Contents</span></h1><p class="c46"><span class="c8"><a class="c5" href="#h.arolcxe0i15c">Abstract</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c5" href="#h.arolcxe0i15c">1</a></span></p><p class="c9"><span class="c8"><a class="c5" href="#h.6ks17bycdnei">Table of Contents</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c5" href="#h.6ks17bycdnei">2</a></span></p><p class="c9"><span class="c22"><a class="c5" href="#h.3rrl7iirerx9">Introduction</a></span><span class="c22">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c22"><a class="c5" href="#h.3rrl7iirerx9">3</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.p03zsxtdci98">Home Equity Line of Credit</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.p03zsxtdci98">3</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.m8iimuc11ozk">The Importance of Interpretability in Financial Data</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.m8iimuc11ozk">3</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.9x8r5r20fqxt">The Needs of Monotonicity Constraints</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.9x8r5r20fqxt">3</a></span></p><p class="c9"><span class="c8"><a class="c5" href="#h.cl6celd8v2o">Data Preprocessing</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c5" href="#h.cl6celd8v2o">4</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.ugf9ntsx65ht">Missing Value Imputation</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.ugf9ntsx65ht">4</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.wyspxej4oyyz">Outlier Analysis</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.wyspxej4oyyz">4</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.jt0lk9x43ij1">Correlation Analysis</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.jt0lk9x43ij1">4</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.cyc9ysobg09t">Analysis of Individual Features</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.cyc9ysobg09t">5</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.ptp2o9w1ifpg">Feature Selection and Its Influence on Model Implementations</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.ptp2o9w1ifpg">5</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.7luhmrknm0ag">Subsidiary Processes of Data Preprocessing</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.7luhmrknm0ag">6</a></span></p><p class="c9"><span class="c8"><a class="c5" href="#h.a44ky6tdvilu">Models Without Monotonicity Constraints</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c5" href="#h.a44ky6tdvilu">6</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.12e5u3b4u3fn">Model Selections</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.12e5u3b4u3fn">6</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.math631excka">Logistic Regressions</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.math631excka">7</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.papnctjmj4eu">General Additive Models</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.papnctjmj4eu">7</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.z1u1zlwt60km">Support Vector Machines</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.z1u1zlwt60km">7</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.66txw8s3h9j2">Decision Tree</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.66txw8s3h9j2">7</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.e3uceuikn9w9">Gradient Boosting: XGBoost</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.e3uceuikn9w9">8</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.qi9t187cc00z">Artificial Neural Network</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.qi9t187cc00z">8</a></span></p><p class="c9"><span class="c8"><a class="c5" href="#h.aiajxm8k14dz">Models With Monotonicity Constraints</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c5" href="#h.aiajxm8k14dz">8</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.ch4u8bxz9l9h">General Additive Model</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.ch4u8bxz9l9h">8</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.m3mg9l7bysw9">Gradient Boosting: XGBoost</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.m3mg9l7bysw9">9</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.q4bca9r85bpo">Monotone MLP</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.q4bca9r85bpo">9</a></span></p><p class="c9"><span class="c8"><a class="c5" href="#h.dd7paisktzfk">Final Model Selection and Further Model Agnostics</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c5" href="#h.dd7paisktzfk">10</a></span></p><p class="c15"><span class="c3"><a class="c5" href="#h.nfkk5nyzznc6">Why XGBoost?</a></span><span class="c3">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3"><a class="c5" href="#h.nfkk5nyzznc6">10</a></span></p><p class="c44"><span class="c8"><a class="c5" href="#h.3gi1iyii2trb">References</a></span><span class="c8">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c8"><a class="c5" href="#h.3gi1iyii2trb">11</a></span></p><h1 class="c10 c29" id="h.j1ksdbza9u40"><span class="c17"></span></h1><h1 class="c10" id="h.3rrl7iirerx9"><span class="c17">Introduction</span></h1><h2 class="c25" id="h.p03zsxtdci98"><span class="c2">Home Equity Line of Credit</span></h2><p class="c10"><span class="c3">A Home Equity Line of Credit , or HELOC is a loan in which the lender agrees to lend a maximum amount within an agreed period of time. The HELOC data contains anonymized credit applications of HELOC credit lines. It introduces a dataset containing 23 features influencing the responsible variable, &lsquo;RiskFlag&rsquo;. Among 10,459 observations, 5,000 of them are classified as &lsquo;Good&rsquo; which means that clients repaid their HELOC account within 2 years. Rest of them are classified as &lsquo;Bad&rsquo;.</span></p><p class="c10"><span class="c7 c13">Credit scoring is a statistical analysis for banks and other lenders to perform before deciding on extending or denying a person&#39;s credit. Due to the increasing number of applications for loans received on a daily basis, it becomes imperative to come up with a model to decide if a person is risky or not.</span></p><h2 class="c24" id="h.m8iimuc11ozk"><span class="c2">The Importance of Interpretability in Financial Data</span></h2><p class="c37"><span class="c1">In financial data like HELOC, the interpretability of a predictive model is crucial. The interpretable models give causal relationships between input data and conclusions. Hence, the model can explain why a certain person can not get a loan. Compared to a blax box, interpretable models reduce the human&#39;s suspicions on the system&rsquo;s conclusion. Companies can easily make decisions with trustworthy systems and customers can easily accept the results.</span></p><h2 class="c24" id="h.9x8r5r20fqxt"><span class="c2">The Needs of Monotonicity Constraints</span></h2><p class="c37"><span class="c7 c21">The monotonic function is a function that is either not entirely increasing or not entirely decreasing. With monotonicity constraints in models, the oscillatory behaviour would be removed. Companies often implement monotonicity constraints in their predictive models to make logical and ethical decisions. Without monotonicity constraints, they may have wrong decisions such that a person with lower credit still gets approved. </span></p><p class="c10 c16"><span class="c3"></span></p><h1 class="c10" id="h.cl6celd8v2o"><span class="c17">Data Preprocessing</span></h1><h2 class="c25" id="h.ugf9ntsx65ht"><span class="c2">Missing Value Imputation</span></h2><p class="c10"><span>As the missing values in the dataset can have effects on the conclusion, we imputed missing values by the property of each feature. The missing values in the dataset are recorded as &lsquo;</span><span class="c6">-7 (Record or No Investigation)</span><span>&rsquo;, &lsquo;</span><span class="c6">-8 (Usable/Valid trades or inquiries)</span><span>&rsquo; and &lsquo;-</span><span class="c6">9 (Condition not met)</span><span class="c3">&rsquo;. Initially, the missing values are replaced with NaN values. </span></p><p class="c10"><span>By plotting the histograms , distributions and box plots of each features, we considered &lsquo;</span><span class="c6">x2 (Months Since Oldest Trade Open)</span><span>&rsquo;, &lsquo;</span><span class="c6">x5 (Number of Satisfactory Trades)</span><span>&rsquo;, &lsquo;</span><span class="c6">x8 (Percent Trades Never Delinquent)&rsquo;</span><span>, &lsquo;</span><span class="c6">x13 (Number of Trades Open in Last 12 Months)</span><span>&rsquo;, &lsquo;</span><span class="c6">x18 (Net Fraction Revolving Burden)</span><span>&rsquo; and &lsquo;</span><span class="c6">x20 (Number of Revolving Trades with Balance)</span><span class="c3">&rsquo; as skewed distributions. Therefore, the missing values of these 6 features are imputed with the median of each feature.</span></p><p class="c10"><span>For the distributions of feature &lsquo;</span><span class="c6">x10 (Max Delq/Public Records Last 12 Months)</span><span>&rsquo; and &lsquo;</span><span class="c6">x11 (Max Delinquency Ever)</span><span class="c3">&rsquo;, they were mostly based on the feature&rsquo;s mode. The missing values of these 2 features are imputed with the mode of the feature. For other features, the missing values are imputed with their medians.</span></p><h2 class="c25" id="h.wyspxej4oyyz"><span class="c2">Outlier Analysis</span></h2><p class="c10"><span class="c3">Including the outliers into the model may reduce the predictability of models. As the box plots show too many outliers in the dataset, we choose to conduct interquartile range (IQR) analysis. We considered the observation that is outside of 3 standard deviations from the mean as an outlier. In the training set, 16 observations are considered as outliers.</span></p><h2 class="c25" id="h.jt0lk9x43ij1"><span class="c2">Correlation Analysis</span></h2><p class="c10"><span>Existence of strong multicollinearity may impact the performance of models. From the heat map, the correlation between features are analyzed. The feature &lsquo;</span><span class="c6">x6 (Number of Trades 60+ Ever)</span><span>&rsquo; and &lsquo;</span><span class="c6">x7 (Number of Trades 90+ Ever)</span><span>&rsquo; </span><span>are highly correlated (0.89). Also, &lsquo;</span><span class="c6">x16 (Number of Inq Last 6 Months)</span><span>&rsquo; and &lsquo;</span><span class="c6">x17 (Number of Inq Last 6 Months excl 7 days)</span><span>&rsquo; are extremely highly correlated (0.99). In general, &lsquo;</span><span class="c6">x1 (Consolidated version of risk markers)&rsquo;</span><span class="c3">&nbsp;is highly correlated with other features among all features.</span></p><h2 class="c25" id="h.cyc9ysobg09t"><span class="c2">Analysis of Individual Features</span></h2><p class="c10"><span>We p</span><span>lotted distributions of each feature grouped by RiskFlag to intuitively explain each feature. </span><span class="c13">For </span><span class="c4">&#39;x6 Number Trades 60+ Ever&#39; </span><span class="c13">and </span><span class="c4">&#39;x7 Number Trades 90+ Ever&#39;,</span><span class="c13">&nbsp;people with bad risk had lower number of trades than people with good risk. For </span><span class="c4">&#39;x10 Max Delq/Public Records Last 12 Months&#39; </span><span class="c13">and </span><span class="c4">&#39;x11 Max Delinquency Ever&#39;</span><span class="c13">, people with good risk had less delinquent trades, which were mostly &#39;unknown&#39;,&#39;current and never delinquent&#39;, etc. For </span><span class="c4">&#39;x18 Net Fraction Revolving Burden&#39;, &#39;x22 Number Bank/Natl Trades w high utilization</span><span class="c13 c22">&nbsp;</span><span class="c4">ratio&#39;</span><span class="c13">&nbsp;and </span><span class="c4">&#39;x23 Percent Trades with Balance&#39;,</span><span class="c14 c13">&nbsp;the people with good risk had lower fraction of revolving burden, lower number of trades with high utilization ratio and lower percent trades with balance.</span></p><h2 class="c25" id="h.ptp2o9w1ifpg"><span class="c2">Feature Selection and Its Influence on Model Implementations</span></h2><p class="c10"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 328.00px;"><img alt="" src="images/image4.png" style="width: 624.00px; height: 328.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c10"><span>Based on the missing value frequencies of </span><span class="c6">&lsquo;</span><span class="c4 c7">x</span><span class="c4 c7">9 (Months Since Most Recent Delinquency), &lsquo;x15 (Months Since Most Recent Inq excl 7days)&rsquo;</span><span class="c7 c13">&nbsp;and &lsquo;</span><span class="c4 c7">x19 (Net Fraction Installment Burden)&rsquo; </span><span class="c7 c13 c14">are significantly higher than other features, they are excluded in our model.</span></p><p class="c10"><span class="c14 c7 c13">From the outlier analysis, 16 observations that are considered as outliers in the training set are removed.</span></p><p class="c10"><span class="c7 c13">From the heat map, Since &lsquo;</span><span class="c4 c7">x6 (Number Trades 60+ Ever)&rsquo;</span><span class="c7 c13">&nbsp;and &lsquo;</span><span class="c4 c7">x7 (Number Trades 90+ Ever)&rsquo; </span><span class="c7 c13">are highly correlated (0.89), and &lsquo;</span><span class="c4 c7">x16 (Number of Inq Last 6 Months)</span><span class="c7 c13">&rsquo; and &lsquo;</span><span class="c4 c7">x17 (Number of Inq Last 6 Months excl 7days)&rsquo; </span><span class="c14 c7 c13">are extremely highly correlated (0.99), one feature from each pair is dropped.</span></p><p class="c10"><span class="c7 c13">Therefore, the dropped features are &lsquo;</span><span class="c4 c7">x7 (Number Trades 90+ Ever)&rsquo;, &lsquo;x9 (Months Since Most Recent Delinquency), &lsquo;x15 (Months Since Most Recent Inq excl 7days)&rsquo;</span><span class="c7 c13">&nbsp;, &lsquo;</span><span class="c4 c7">x17 (Number of Inq Last 6 Months excl 7days)&rsquo; </span><span class="c7 c13">and</span><span class="c4 c7">&nbsp;</span><span class="c7 c13">&lsquo;</span><span class="c4 c7">x19 (Net Fraction Installment Burden)&rsquo; .</span></p><h2 class="c25" id="h.7luhmrknm0ag"><span class="c2">Subsidiary Processes of Data Preprocessing</span></h2><p class="c10"><span class="c3">The two classes &lsquo;Bad&rsquo; and &lsquo;Good&rsquo; are replaced by binary numbers, 0 and 1 respectively.</span></p><p class="c10"><span>As </span><span class="c4">&#39;x10 Max Delq/Public Records Last 12 Months&#39; </span><span class="c13">and </span><span class="c4">&#39;x11 Max Delinquency Ever&#39;</span><span class="c13">&nbsp;are categorical data, we encoded them. Also, we scaled the data to obtain better performance for some models.</span></p><p class="c10 c16"><span class="c3"></span></p><h1 class="c10" id="h.a44ky6tdvilu"><span class="c17">Models Without Monotonicity Constraints</span></h1><h2 class="c25" id="h.12e5u3b4u3fn"><span class="c2">Model Selections</span></h2><p class="c10"><span>We selected popular models that we felt could adequately predict the test set. Six for the non-monotonicity constrained model and 3 for the monotonicity model. To choose our final model, we tested the models on our test set to obtain an accuracy score, as well as generate a unique way to interpret the data for each model. The final model was chosen based on both the accuracy and the interpretability.</span></p><h2 class="c25" id="h.math631excka"><span class="c2">Logistic Regressions</span></h2><p class="c10"><span class="c3">Accuracy of logistic regression on the testing set = 0.7051</span></p><p class="c10"><span class="c3">Accuracy of logistic regression with IV binning on the testing set = 0.7089</span></p><p class="c10"><span class="c3">The logit regression result allows us to see the importance of each feature based on their z values. The probability of each feature to be relevant can also be seen with the p-values, and any feature with a high value can then be dropped.</span></p><h2 class="c25" id="h.papnctjmj4eu"><span class="c2">General Additive Models</span></h2><p class="c10"><span class="c3">The Accuracy of B-Spline GAM model on testing set: 0.7094</span></p><p class="c10"><span class="c3">The Accuracy of Piecewise ReLu GAM model on testing set: 0.7075</span></p><p class="c10"><span class="c3">The pyGAM package comes with a built-in function to obtain the partial dependence plots for each feature, and from the plots we can see the contribution each feature makes according to the value of the feature. For example, RiskFlag depends more on x1 at higher values, as seen by the increasing partial dependence plots. </span></p><h2 class="c25" id="h.z1u1zlwt60km"><span class="c2">Support Vector Machines</span></h2><p class="c10"><span class="c3">The Accuracy of SVM model with Linear SVC on testing set: 0.7103</span></p><p class="c10"><span class="c3">The Accuracy of Stochastic gradient descent version of SVM on testing set: 0.7108</span></p><p class="c10"><span class="c3">The Accuracy of SVM model with RBF kernel on testing set: 0.7137</span></p><p class="c10"><span class="c3">The Accuracy of SVM model with RBF kernel on testing set: 0.7137</span></p><p class="c10"><span class="c3">The Accuracy of SVM model with RBF kernel with hyperparameter tuning on testing set: 0.7108</span></p><p class="c10"><span class="c3">We can run post-hoc analysis on the model to obtain the partial dependence plots.</span></p><h2 class="c25" id="h.66txw8s3h9j2"><span class="c2">Decision Tree</span></h2><p class="c10"><span class="c3">The Accuracy of Decision Tree on testing set: 0.7089</span></p><p class="c10"><span class="c3">A decision tree diagram can be printed out to analyse the cut-off for each feature on the &nbsp;branches.</span></p><h2 class="c25" id="h.e3uceuikn9w9"><span class="c2">Gradient Boosting: XGBoost</span></h2><p class="c10"><span class="c3">The Accuracy of XGBoost with high learning rate with its optimal estimator=34 on testing set: 0.71702</span></p><p class="c10"><span class="c3">The Accuracy of XGBoost with low learning rate with its optimal estimator=130 on testing set: 0.71941</span></p><p class="c10"><span class="c3">Various methods of interpretation can be obtained post-hoc, including partial dependence plots and SHAP values. As this is our chosen model, the interpretation will be elaborated at the end of the report.</span></p><h2 class="c25" id="h.qi9t187cc00z"><span class="c2">Artificial Neural Network</span></h2><p class="c10"><span class="c3">The Accuracy of MLPClassifier with Piecewise ReLU on testing set: 0.7189</span></p><p class="c10"><span class="c3">Similarly to XGBoost, we can obtain post-hoc analysis with SHAP values to find the feature importance or the influence of each individual value.</span></p><h1 class="c10 c29" id="h.t7r3xq7c7msz"><span class="c17"></span></h1><h1 class="c10" id="h.aiajxm8k14dz"><span class="c17">Models With Monotonicity Constraints</span></h1><h2 class="c25" id="h.ch4u8bxz9l9h"><span class="c2">General Additive Model</span></h2><p class="c10"><span class="c3">To control the overfitting, we added monotonicity constraints to the logistic General Additive Model. By adding monotonicity constraints, we can draw more reliable conclusions. </span></p><p class="c10"><span class="c3">As the monotonicity constraints in the data dictionary show the monotonicity constraint of each feature when the &lsquo;Bad&rsquo; is encoded as 1, we interpreted them oppositely. According to each feature&rsquo;s property, we added &lsquo;constraints = &lsquo;monotonic_inc&rsquo;&rsquo; or &lsquo;constraints = &lsquo;monotonic_dec&rsquo;&rsquo; in the spline terms. With the features that have no monotonicity constraints and categorical data, the factor terms are used.</span></p><p class="c10"><span class="c3">The accuracy on the training set for GAM with monotonicity constraints is 0.7006.</span></p><p class="c10"><span class="c3">The accuracy on the test set for GAM with monotonicity constraints is 0.7032.</span></p><h2 class="c25" id="h.m3mg9l7bysw9"><span class="c2">Gradient Boosting: XGBoost</span></h2><p class="c10"><span class="c3 c7">We have used a 5-fold cross-validation and early-stopping on the training dataset to determine the optimal number of trees. Then, we use the entire training set to train the model and evaluate its performance on the testset. </span></p><p class="c10"><span class="c7">In </span><span class="c12 c7">Xgboost</span><span class="c7 c22">, </span><span class="c12 c7">&#39;monotone_constraints&#39;</span><span class="c7">&nbsp;is where the monotonicity constraints are set. The values &lsquo;-1&rsquo;, &lsquo;0&rsquo;, &lsquo;1&rsquo; imply monotonically increasing, not monotonically constrained and monotonically decreasing respectively. Evaluation on the test set is based on </span><span class="c7 c12">&#39;error&#39;</span><span class="c3 c7">, which is one of the evaluation metrics of xgboost. Prediction accuracy is calculated using [1-error]. </span></p><p class="c10"><span class="c3 c7">Relationship between RiskFlag and each feature variable can be shown in the partial dependence plot. To plot the partial dependence, we have created a function where a grid of values of a feature variable is sampled and for each value, every row of that variable is replaced with the sampled values.Then the function calculates the average prediction. </span></p><p class="c10"><span class="c3">The accuracy on the training set for XGBoost with monotonicity constraints is 0.7285.</span></p><p class="c10"><span>The accuracy on the test set for XGBoost with monotonicity constraints is 0.7141.</span></p><h2 class="c25" id="h.q4bca9r85bpo"><span class="c2">Monotone MLP</span></h2><p class="c10"><span class="c3">One of the important findings in order to apply monotonicity constraints in ANN is to guarantee that keeping all the weights in the model non-negative for case of increasing constraint (Zhang and Zhang, 1999). The &lsquo;monmlp&rsquo; package was constructed based on the modified feedforward network structure suggested by Zhang and Zhang in 1999.</span></p><p class="c10"><span class="c3">In their network structure, they transformed the weight into the exponential form, which does not take negative value into account. Furthermore, it avoids the issues of domain restrictions. They derived the gradient calculation of network using transformed weights to prove the network structure in monotone. </span></p><p class="c10"><span class="c3">In order to apply the idea into our HELOC binary classification problem, we have transformed the predictive values into sigmoid functions, and regarded any values below 0.5 as 0 and any values above 0.5 as 1.</span></p><p class="c10"><span class="c3">The accuracy of the model on test set was reported as 0.7156.</span></p><p class="c10"><span class="c3">According to the research done by Lang (2005), the monotonic MLP can enhance the model performance independently from the quality of training data set or complexity in terms of multidimensionality. Hence, the monotonic MLP have a potential to give the best performance among other models constrained with monotonicity.</span></p><p class="c10"><span class="c3">However there are two problems exist in order for monotone MLP is chosen for the final model. First, such model confronts the problem of restriction in weights which hinders the nature of learning algorithm. Thereby, the interpretation of model using existing model-agnostics is even harder. Secondly, the &lsquo;monmlp&rsquo; package can only use upto two layers, which have a potential in oversimplification. Nonetheless, the second issue can be solved with using lately developed model. </span></p><h1 class="c10 c29" id="h.nsc4ctxip3sy"><span class="c17"></span></h1><h1 class="c10" id="h.dd7paisktzfk"><span class="c17">Final Model Selection and Further Model Agnostics</span></h1><h2 class="c25" id="h.nfkk5nyzznc6"><span class="c2">Why XGBoost?</span></h2><p class="c10"><span class="c3">Gradient boosting method is powerfully performing machine learning model among widely used machine learning models. It utilizes both classification and regression in learning via negative gradients. This implies that there is a high possibility of capturing the potential relationship between each features and response variable. As shown in the above experiments, the XGBoost method resulted in high performance in general. </span></p><p class="c10"><span class="c3">However, comparing XGBoost from different white-box models, it is factual that the interpretability of the model is comparatively low. Although there are some tools for model-agnostic in order to capture the global and local behavior of the model, still the decision processes made by the model are in question. Nonetheless, along with the consideration of information demand from financial industry, we conclude that capturing global and local behavior of the model would suffice. Hence, it is worthwhile to trade-off interpretability with model performance, as we notice the difference in performance between XGBoost and other white-box models is significant.</span></p><p class="c30"><span class="c3">In order to increase the interpretability of XGBoost, we have used several methods for model-agnostics. This section includes: feature importance, partial dependence plots, bivariate partial dependence plots, and local behavior of the model. All the results can be find in the enclosed jupyter notebook.</span></p><p class="c10 c16"><span class="c3"></span></p><hr style="page-break-before:always;display:none;"><p class="c20 c16"><span class="c3"></span></p><h1 class="c32" id="h.3gi1iyii2trb"><span class="c17">References</span></h1><p class="c20"><span>Molnar, C. (2020, November 30). Interpretable Machine Learning. From </span><span class="c28"><a class="c5" href="https://www.google.com/url?q=https://christophm.github.io/interpretable-ml-book/interpretability-importance.html&amp;sa=D&amp;source=editors&amp;ust=1612374075531000&amp;usg=AOvVaw2lAYWHSa1qwU2gSiRBZVkZ">https://christophm.github.io/interpretable-ml-book/interpretability-importance.html</a></span></p><p class="c20"><span>Tiwari, A. (2020, May 01). Application of Monotonic Constraints in Machine Learning Models. From </span><span class="c28"><a class="c5" href="https://www.google.com/url?q=https://medium.com/analytics-vidhya/application-of-monotonic-constraints-in-machine-learning-models-334564bea616&amp;sa=D&amp;source=editors&amp;ust=1612374075532000&amp;usg=AOvVaw2Lx3-BfiFIXARml24zTNL_">https://medium.com/analytics-vidhya/application-of-monotonic-constraints-in-machine-learning-models-334564bea616</a></span></p><p class="c20"><span>Kurzelewski, T., &amp; Radzikowski, T. (2020, October 14). XAI Stories. From </span><span class="c28"><a class="c5" href="https://www.google.com/url?q=https://pbiecek.github.io/xai_stories/story-heloc-credits.html&amp;sa=D&amp;source=editors&amp;ust=1612374075532000&amp;usg=AOvVaw14sL3aEqaA66GO6MEifkj-">https://pbiecek.github.io/xai_stories/story-heloc-credits.html</a></span></p><p class="c20"><span>Zhang, H., &amp; Zhang, Z. (1999). Feedforward Networks with Monotone Constraints. </span><span class="c1 c18">DOI: </span><span class="c7 c47"><a class="c5" href="https://www.google.com/url?q=https://doi.org/10.1109/IJCNN.1999.832655&amp;sa=D&amp;source=editors&amp;ust=1612374075533000&amp;usg=AOvVaw3FC1Aa9h241pt10NljYKr1">10.1109/IJCNN.1999.832655</a></span></p><p class="c20"><span class="c3">Lang B. (2005) Monotonic Multi-layer Perceptron Networks as Universal Approximators. DOI https://doi.org/10.1007/11550907_6</span></p><p class="c20 c16"><span class="c3"></span></p><p class="c20 c16"><span class="c3"></span></p><p class="c20 c16"><span class="c3"></span></p><p class="c20 c16"><span class="c3"></span></p><p class="c10 c16"><span class="c3"></span></p></body></html>